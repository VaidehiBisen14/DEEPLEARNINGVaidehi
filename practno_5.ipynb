{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6W3qNxh7KrpogCV+p9ThP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaidehiBisen14/DEEPLEARNINGVaidehi/blob/main/practno_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "RNN (LSTM) classifier for breast tumor vs normal.\n",
        "\n",
        "Assumptions:\n",
        "- Dataset at ./Process_Data.csv\n",
        "- The script attempts to auto-detect the target column (looks for common names or any binary column).\n",
        "- If non-numeric feature columns are present they will be dropped (you can add encoding).\n",
        "- Uses timesteps=1 (features are provided as a single timestep vector) — common for tabular data when using RNN/LSTM.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "DATA_PATH = \"Process_Data.csv\"   # adjust if needed\n",
        "\n",
        "def load_and_inspect(path):\n",
        "    df = pd.read_csv(path)\n",
        "    print(\"Loaded:\", path)\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Columns:\", df.columns.tolist())\n",
        "    print(df.head())\n",
        "    return df\n",
        "\n",
        "def detect_target(df):\n",
        "    # Try common target names first\n",
        "    possible_targets = ['target', 'label', 'class', 'Tissue', 'tissue', 'diagnosis', 'Diagnosis', 'Outcome', 'outcome']\n",
        "    for name in possible_targets:\n",
        "        if name in df.columns:\n",
        "            return name\n",
        "    # otherwise pick a column with exactly two unique values\n",
        "    for c in df.columns:\n",
        "        if df[c].nunique() == 2:\n",
        "            return c\n",
        "    # fallback: try to find a numeric column with small unique count\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_integer_dtype(df[c]) and df[c].nunique() <= 10 and df[c].nunique() != df.shape[0]:\n",
        "            return c\n",
        "    raise ValueError(\"Could not auto-detect a binary target column. Please provide the target column name.\")\n",
        "\n",
        "def prepare_data(df, target_col):\n",
        "    X = df.drop(columns=[target_col]).copy()\n",
        "    y = df[target_col].copy()\n",
        "\n",
        "    # Drop purely non-numeric columns for simplicity (you can add encoding here)\n",
        "    non_numeric = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    if non_numeric:\n",
        "        print(\"Dropping non-numeric columns (for this demo):\", non_numeric)\n",
        "        X = X.drop(columns=non_numeric)\n",
        "\n",
        "    # Fill NaNs\n",
        "    if X.isna().sum().sum() > 0:\n",
        "        print(\"Filling missing feature values with column mean.\")\n",
        "        X = X.fillna(X.mean())\n",
        "\n",
        "    # Encode target to 0/1\n",
        "    if y.dtype == 'object' or y.dtype.name == 'category':\n",
        "        le = LabelEncoder()\n",
        "        y_enc = le.fit_transform(y)\n",
        "        classes = le.classes_.tolist()\n",
        "    else:\n",
        "        le = None\n",
        "        y_enc = LabelEncoder().fit_transform(y) if y.nunique() <= 10 else y.values\n",
        "        classes = np.unique(y_enc).tolist()\n",
        "\n",
        "    return X.values, y_enc, X.columns.tolist(), classes, le\n",
        "\n",
        "def build_model(timesteps, n_features):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(timesteps, n_features), return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    df = load_and_inspect(DATA_PATH)\n",
        "    target_col = detect_target(df)\n",
        "    print(\"Detected target column:\", target_col)\n",
        "    print(\"Target distribution:\\n\", df[target_col].value_counts())\n",
        "\n",
        "    X, y, feature_names, classes, label_encoder = prepare_data(df, target_col)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # Scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # RNN shape: (samples, timesteps, features). We'll use timesteps=1\n",
        "    timesteps = 1\n",
        "    n_features = X_train_scaled.shape[1]\n",
        "    X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], timesteps, n_features))\n",
        "    X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], timesteps, n_features))\n",
        "    print(\"RNN input shape:\", X_train_rnn.shape)\n",
        "\n",
        "    model = build_model(timesteps, n_features)\n",
        "    print(model.summary())\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
        "        ModelCheckpoint(\"best_rnn_model.h5\", monitor='val_loss', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_rnn, y_train,\n",
        "        validation_split=0.15,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    loss, acc = model.evaluate(X_test_rnn, y_test, verbose=0)\n",
        "    print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.4f}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_prob = model.predict(X_test_rnn).ravel()\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    print(\"Classification report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[str(c) for c in classes]))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Plot history\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(['train','val'])\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(['train','val'])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Save model & scaler\n",
        "    model.save(\"rnn_breast_model.h5\")\n",
        "    np.save(\"scaler_mean.npy\", scaler.mean_)\n",
        "    np.save(\"scaler_scale.npy\", scaler.scale_)\n",
        "    print(\"Saved rnn_breast_model.h5 and scaler params.\")\n",
        "\n",
        "    # Show sample predictions\n",
        "    sample_df = pd.DataFrame({\n",
        "        'pred_prob': y_prob[:10],\n",
        "        'pred_label': y_pred[:10],\n",
        "        'true_label': y_test[:10]\n",
        "    })\n",
        "    print(\"\\nSample predictions (first 10):\\n\", sample_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cbvrIeqVfHNb",
        "outputId": "4e17bf29-f8e2-46ef-b707-23f95a260282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: Process_Data.csv\n",
            "Shape: (100000, 21)\n",
            "Columns: ['Bill_ID', 'Client_ID', 'State', 'Original_Charge', 'Reduction', 'First_Activity', 'Last_Activity', 'Team_1_Start', 'Team_1_End', 'Team_2_Start', 'Team_2_End', 'Team_3_Start', 'Team_3_End', 'Completed', 'Closed', 'Type_A', 'Type_B', 'Type_C', 'Type_D', 'Type_E', 'Type_F']\n",
            "   Bill_ID  Client_ID State  Original_Charge  Reduction    First_Activity  \\\n",
            "0   230000     101234    VA            47.00      47.00   11/15/2018 0:15   \n",
            "1   230001     208827    CA           371.00     272.19  11/15/2018 22:07   \n",
            "2   230002      93156    AZ           337.67      35.96   11/21/2018 6:19   \n",
            "3   230003     174724    NY           194.35     194.35    12/3/2018 7:50   \n",
            "4   230004      92975    MI           200.00      61.22   12/12/2018 3:52   \n",
            "\n",
            "      Last_Activity      Team_1_Start        Team_1_End     Team_2_Start  ...  \\\n",
            "0  11/22/2018 17:04   11/15/2018 0:15   11/15/2018 0:16  11/19/2018 8:24  ...   \n",
            "1    12/3/2018 7:44  11/15/2018 22:07  11/15/2018 22:07              NaN  ...   \n",
            "2    12/5/2018 7:16   11/21/2018 6:19   11/21/2018 6:20              NaN  ...   \n",
            "3    1/1/2019 13:32               NaN               NaN   12/3/2018 7:50  ...   \n",
            "4    3/1/2019 20:37   12/12/2018 3:52   12/12/2018 3:52              NaN  ...   \n",
            "\n",
            "       Team_3_Start        Team_3_End         Completed          Closed  \\\n",
            "0  11/20/2018 10:36  11/20/2018 10:36  11/21/2018 20:01             NaN   \n",
            "1  11/16/2018 12:18  11/16/2018 12:18  11/19/2018 19:34  12/3/2018 7:44   \n",
            "2  11/27/2018 18:34  11/27/2018 18:34  11/30/2018 20:03             NaN   \n",
            "3   12/3/2018 14:06   12/3/2018 14:06   12/4/2018 19:37  1/1/2019 13:32   \n",
            "4               NaN               NaN  12/26/2018 20:00             NaN   \n",
            "\n",
            "  Type_A  Type_B  Type_C  Type_D  Type_E  Type_F  \n",
            "0      0       0       1       0       0       0  \n",
            "1      0       0       0       0       0       0  \n",
            "2      0       0       0       0       0       0  \n",
            "3      0       0       0       1       0       0  \n",
            "4      0       0       0       0       0       0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Detected target column: Type_A\n",
            "Target distribution:\n",
            " Type_A\n",
            "0    97027\n",
            "1     2973\n",
            "Name: count, dtype: int64\n",
            "Dropping non-numeric columns (for this demo): ['State', 'First_Activity', 'Last_Activity', 'Team_1_Start', 'Team_1_End', 'Team_2_Start', 'Team_2_End', 'Team_3_Start', 'Team_3_End', 'Completed', 'Closed']\n",
            "RNN input shape: (80000, 1, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m18,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,057\u001b[0m (82.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,057</span> (82.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,057\u001b[0m (82.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,057</span> (82.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9689 - loss: 0.1421 - val_accuracy: 0.9711 - val_loss: 0.1090\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9700 - loss: 0.1175 - val_accuracy: 0.9714 - val_loss: 0.1075\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 6s - 3ms/step - accuracy: 0.9701 - loss: 0.1151 - val_accuracy: 0.9716 - val_loss: 0.1051\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9700 - loss: 0.1143 - val_accuracy: 0.9712 - val_loss: 0.1043\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 9s - 4ms/step - accuracy: 0.9703 - loss: 0.1131 - val_accuracy: 0.9716 - val_loss: 0.1041\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9703 - loss: 0.1122 - val_accuracy: 0.9715 - val_loss: 0.1038\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9702 - loss: 0.1122 - val_accuracy: 0.9714 - val_loss: 0.1038\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 6s - 3ms/step - accuracy: 0.9703 - loss: 0.1114 - val_accuracy: 0.9718 - val_loss: 0.1034\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9704 - loss: 0.1114 - val_accuracy: 0.9716 - val_loss: 0.1029\n",
            "Epoch 10/100\n",
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9704 - loss: 0.1109 - val_accuracy: 0.9717 - val_loss: 0.1029\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9704 - loss: 0.1099 - val_accuracy: 0.9720 - val_loss: 0.1026\n",
            "Epoch 12/100\n",
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9704 - loss: 0.1097 - val_accuracy: 0.9717 - val_loss: 0.1030\n",
            "Epoch 13/100\n",
            "2125/2125 - 6s - 3ms/step - accuracy: 0.9704 - loss: 0.1103 - val_accuracy: 0.9721 - val_loss: 0.1028\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9705 - loss: 0.1087 - val_accuracy: 0.9719 - val_loss: 0.1021\n",
            "Epoch 15/100\n",
            "2125/2125 - 6s - 3ms/step - accuracy: 0.9706 - loss: 0.1092 - val_accuracy: 0.9721 - val_loss: 0.1023\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9705 - loss: 0.1089 - val_accuracy: 0.9722 - val_loss: 0.1021\n",
            "Epoch 17/100\n",
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9705 - loss: 0.1086 - val_accuracy: 0.9717 - val_loss: 0.1026\n",
            "Epoch 18/100\n",
            "2125/2125 - 9s - 4ms/step - accuracy: 0.9705 - loss: 0.1086 - val_accuracy: 0.9719 - val_loss: 0.1024\n",
            "Epoch 19/100\n",
            "2125/2125 - 7s - 3ms/step - accuracy: 0.9707 - loss: 0.1083 - val_accuracy: 0.9717 - val_loss: 0.1030\n",
            "Epoch 20/100\n",
            "2125/2125 - 6s - 3ms/step - accuracy: 0.9707 - loss: 0.1080 - val_accuracy: 0.9719 - val_loss: 0.1024\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2125/2125 - 10s - 5ms/step - accuracy: 0.9706 - loss: 0.1082 - val_accuracy: 0.9721 - val_loss: 0.1018\n",
            "Epoch 22/100\n"
          ]
        }
      ]
    }
  ]
}